# KappArmor - AI Development Instructions

## Project Overview

This Go app provides dynamic loading and unloading of AppArmor profiles to Kubernetes cluster Linux nodes from a configmap.  
The app will be managed by a K8S DaemonSet.  
The custom profiles deployed in the configmap will be copied in `/etc/apparmor.d/custom` by default since apparmor_parser needs the profiles definitions also to remove them.
Once a configmap will be detected, Kapparmor will notice missing or updated profiles and it will update them in the host apparmor cache and from the node directory.  

### Key Characteristics
- **Language**: Go 1.25
- **Architecture**: Microservice
- **Target**: AKS and native K8s clusters
- **Security**: Enterprise-grade with SSDLC practices

## Development Philosophy

### Core Principles
1. **Minimalism**: Write less code, achieve more functionality
2. **Security First**: SSDLC and defensive coding throughout
3. **Standard Libraries**: Prefer Go standard libraries over external dependencies
4. **Quality**: High-quality, tested, and reviewed code
5. **Performance**: Efficient resource utilization and response times

### Code Quality Standards

#### Mandatory Quality Gates
- **Static Analysis**: `go vet`, `go sec`, `go lint` must pass
- **Testing**: Comprehensive `go test` coverage (>80%)
- **Security**: `gosec` security analysis. Testing files should be ignored.
- **No silent breaking changes**: Changes in behavior should be alerted and documented
- **Documentation**: Clear comments and godoc

#### Code Review Checklist
- [ ] Input validation and sanitization
- [ ] Error handling with proper context
- [ ] Resource cleanup and memory management
- [ ] Security considerations (authentication, authorization, data protection)
- [ ] Performance implications
- [ ] Test coverage for new functionality

## Architecture Guidelines

### Project Structure
```sh
.
├── build   # Main scripts to validate, lint and build container files
├── charts
│   └── kapparmor       # Main Helm chart folder
│       ├── profiles    # built-in sample apparmor profiles shipped with the Helm chart
│       └── templates   # Helm templates
│           └── tests
├── config              # shared config vars to make the project building consistent (go version, chart version...)
├── docs
├── go                  # app code and unit tests
│   └── src
│       ├── app
│       │   └── profile_test_samples
│       │       └── positive_tests
│       └── docs
├── img
└── test    # K8S resources for integration testing
```

### Design Patterns

#### 2. Defensive Coding Techniques
- Input validation
- Additional validation
- Context cancellation management
- Error handling
- Always clean up resources. Cleanup on failure.

## Security Requirements

### SSDLC Integration
1. **Threat Modeling**: Identify and mitigate security threats
2. **Secure Coding**: Follow OWASP guidelines and Go security best practices. Vulnerability scanning.
5. **Authorization**: Least privileges principle
6. **Data Protection**: Encryption at rest and in transit where needed. Limit open ports and exposed APIs.
7. **Audit Logging**: Comprehensive security event logging

### Optimization Strategies
1. **Connection Pooling**: Reuse database and HTTP connections
2. **Caching**: Implement intelligent caching for frequently accessed data
3. **Async Processing**: Non-blocking operations where possible
4. **Resource Limits**: Proper resource quotas and limits
5. **Monitoring**: Comprehensive metrics and alerting

## Testing Strategy

### Test Pyramid
1. **Unit Tests**: Fast, isolated, comprehensive coverage. Add fuzzy testing after unit tests are succeeding.
2. **Integration Tests**: Component interaction testing
3. **End-to-End Tests**: Full workflow validation.
4. **Security Tests**: Penetration testing, vulnerability scanning, reduce attack surface.
5. **Performance Tests**: Load testing, stress testing


## Design Choices and Trade-offs

### 1. Standard Libraries vs External Dependencies

**Choice**: Prefer Go standard libraries
- **Pros**: Reduced attack surface, better performance, easier maintenance
- **Cons**: May require more custom implementation
- **Trade-off**: Acceptable complexity increase for security and stability

### 2. Synchronous vs Asynchronous Processing

**Choice**: Hybrid approach
- Synchronous for immediate feedback
- Asynchronous for long-running operations
- **Trade-off**: Better user experience with complexity in state management

## AI Development Settings

### Context for AI Prompts
When working with this project, AI should:

1. **Understand the Domain**: K8S v1.30+ running a security critical, privileged app in a Daemonset over linux nodes.
2. **Follow Go Best Practices**: Idiomatic Go code, proper error handling
3. **Consider Security**: Always think about security implications
4. **Optimize for Performance**: Efficient resource usage
5. **Maintain Quality**: High test coverage, proper documentation
6. **Tested Code**: Always provide working, tested code. Run pre-commit hooks as extra validation.
7. **Performance Impact**: Discuss performance implications
8. **Testing Strategy**: Suggest appropriate tests
9. **Look for breaking changes**: breaking changes should happen only when explicitly expected and documented.
10. **Documentation**: Include relevant comments and documentation



## Monitoring and Observability

### Key Metrics
- **Error Rates**: error rates
- **Resource Usage**: CPU, memory, number of profiles loaded
- **Business Metrics**: TBD

### Logging Standards
Use Go standard slog library for structured logging (https://go.dev/blog/slog).

## References and Resources

### Documentation
- [AppArmor profiles](https://ubuntu.com/server/docs/security-apparmor)
- [Go Security Best Practices](https://golang.org/doc/articles/security.html)


**Note**: This instruction file should be updated as the project evolves. Always consider the latest security practices and performance optimizations when making changes.
